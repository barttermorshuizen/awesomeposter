# Story 8.29: Flex Sandbox Conversational Envelope Builder

## Status
Ready for Dev

## Story
**As a** flex sandbox operator,  
**I want** to construct TaskEnvelope payloads through a guided GPT-5 conversation with an expandable JSON preview,  
**so that** I can author rich envelopes quickly without hand-editing raw JSON while still inspecting the full contract.  

**Dependencies:** Story 8.19 (Flex Planner Sandbox UI shell) and Story 8.25 (planner honoring envelope-driven contracts) must remain available in the target environment. (`docs/architecture/flex-agents-server.md#51-taskenvelope`, `docs/architecture/flex-agents-server.md#developer-sandbox`)

## Acceptance Criteria
1. The TaskEnvelope panel replaces the raw `<textarea>` editor with the shared JSON tree viewer used in the Condition Playground, providing expand/collapse nodes, copy-to-clipboard, and syntax highlighting while preserving schema validation via `TaskEnvelopeSchema`. (`src/views/FlexSandboxView.vue`, `src/views/ConditionPlaygroundView.vue`, `docs/architecture/flex-agents-server.md#51-taskenvelope`)
2. Operators can toggle a “Raw JSON Edit” drawer/modal for advanced tweaks; edits round-trip through `TaskEnvelopeSchema` validation before refreshing the tree view, and validation errors surface inline without breaking existing drafts. (`docs/architecture/flex-agents-server.md#developer-sandbox`, `packages/shared/src/flex/types.ts`)
3. A new conversational builder panel (feature-flagged with the existing sandbox guard) orchestrates a GPT-5 powered dialogue: the assistant asks one schema-aligned question at a time (objective, knobs, policies, contracts, etc.), displays the conversation history, and enables freeform operator responses. (`docs/architecture/flex-agents-server.md#plannerservice-llm-backed`, `server/utils/llm.ts`)
4. After each operator response, the assistant response includes structured deltas that merge into the working `TaskEnvelope`; the UI previews changes, revalidates with `TaskEnvelopeSchema`, highlights any missing required fields, and disables “Run plan” until the envelope is valid. (`docs/architecture/flex-agents-server.md#51-taskenvelope`, `src/views/FlexSandboxView.vue`)
5. Flex sandbox conversation APIs live under `/api/v1/flex/sandbox/envelope/*`, reuse the Nitro runtime’s OpenAI client with a default model of `gpt-5`, respect `USE_FLEX_DEV_SANDBOX`, and never persist envelopes server-side. Errors (rate limits, invalid deltas) surface in the UI with actionable retry guidance. (`packages/flex-agents-server/nitro.config.ts`, `docs/architecture/flex-agents-server.md#14-risks--open-questions`)
6. Automated tests cover the conversation flow (mocked GPT-5 responses) and JSON viewer integration: Vitest component tests assert tree updates + validation messaging, and Nitro tests validate the conversation endpoint contract + model selection. (`docs/architecture/discovery_agent_backend/testing-strategy.md#testing-strategy`)
7. Developer documentation explains enabling the conversational builder, environment variables (`USE_FLEX_DEV_SANDBOX`, `FLEX_OPENAI_DEFAULT_MODEL`), and troubleshooting steps; manual QA verifies the feature stays hidden when the sandbox flag is off and that legacy envelope templates still load. (`docs/architecture/flex-agents-server.md#developer-sandbox`, `docs/architecture/coding-standards.md#documentation`)

## Tasks / Subtasks
- [ ] Swap the sandbox editor to the shared JSON tree component with copy/expand controls and validation wiring. (AC 1)
- [ ] Implement optional raw JSON edit drawer/modal with schema validation and error surfacing. (AC 2)
- [ ] Build GPT-5 conversational builder UI (Pinia store, history display, turn-based prompts) gated by the sandbox flag. (AC 3,4)
- [ ] Add Nitro conversation endpoints that call GPT-5, merge structured deltas, and guard with sandbox + rate limiting. (AC 3-5)
- [ ] Write Vitest/Nitro tests for the JSON viewer flow and conversational endpoints (mocking OpenAI). (AC 6)
- [ ] Update developer documentation and QA checklist for the new workflow + configuration. (AC 7)

## Story Context

**Existing System Integration:**
- Integrates with: `src/views/FlexSandboxView.vue`, `src/components/FlexSandboxPlanInspector.vue`, sandbox feature flag utilities, Nitro sandbox metadata APIs, `server/utils/llm.ts`.
- Technology: Vue 3 + Pinia, TypeScript, Vuetify 3, Nitro server with OpenAI SDK, `@awesomeposter/shared` TaskEnvelope schema.
- Patterns: Feature-flagged developer tooling (Story 8.19), LLM-assisted prompting patterns used by `PlannerService`, JSON tree previews from Condition Playground.

## Acceptance Criteria (Detailed)

### Functional Requirements
1. JSON tree viewer mirrors the conversational envelope state, supports expand/collapse per node, and offers copy/download actions.
2. Conversational assistant bootstraps envelopes from selected templates or defaults, asks targeted follow-ups when fields remain unset, and provides undo for the last assistant delta.
3. Validation banner lists missing/invalid fields and links to the relevant tree nodes; raw edit drawer cannot save invalid JSON.

### Integration Requirements
4. Conversation endpoints run only when `USE_FLEX_DEV_SANDBOX=true`, reuse existing auth, and stream updates back to the client as structured deltas.
5. Server-side GPT requests default to `gpt-5` via `FLEX_OPENAI_DEFAULT_MODEL` but respect overrides; rate limiting and error handling align with existing `FlexRunController` patterns.
6. Envelope deltas never persist server-side; all drafts remain client-local (localStorage) as today.

### Quality Requirements
7. Vitest component tests cover viewer toggle, validation messaging, and conversation-driven updates.
8. Nitro endpoint tests assert GPT invocation parameters, sandbox guard enforcement, and error shaping.
9. Documentation + manual QA checklist updated to reflect new workflow and flag gating.

## Technical Notes
- Reuse the `vue-json-pretty` dependency already bundled for Condition Playground to avoid new packages.
- Conversation delta format should mirror the planner’s policy mutation events to simplify merging.
- Consider exponential backoff or operator-facing retry messaging for OpenAI rate-limit responses.

## Definition of Done
- [ ] Functional requirements met
- [ ] Integration requirements verified
- [ ] Tests pass (unit + integration)
- [ ] Documentation updated
- [ ] Feature gated and flag defaults verified

## Risk and Compatibility Check
- **Primary Risk:** GPT-5 responses generating invalid envelopes or overstepping policy constraints.  
  **Mitigation:** Strict schema validation, delta sanitizer, and ability to undo/abort conversation; keep manual raw edit fallback.
- **Rollback:** Disable sandbox conversational flag to revert to read-only viewer; rerun Story 8.19 editor behavior if needed.

**Compatibility Verification**
- [x] No breaking changes to public APIs
- [x] Database untouched
- [x] UI changes follow existing sandbox patterns
- [x] Performance impact minimal (local validation + rate limiting)

## Validation Checklist
- [x] Story scoped to single feature
- [x] Dependencies satisfied before start
- [x] Acceptance criteria are testable
- [x] Rollback controlled via feature flag
