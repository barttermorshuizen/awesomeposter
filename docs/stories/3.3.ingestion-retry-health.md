# Story 3.3: Retry & Health Monitoring

## Status
Draft

## Story
**As the** ingestion operator,
**I want** transient failures retried with backoff and surfaced in telemetry,
**so that** source issues are transparent without overwhelming the system.

## Acceptance Criteria
1. Transient errors (network timeouts, 5xx) retried up to 3 times with exponential backoff (base 2, max 15 minutes).
2. Permanent errors (4xx except 429) marked without retry and flagged to health status service.
3. Telemetry logs each attempt with result, retry count, and reason code.
4. SSE `ingestion.failed` event emitted on final failure, consumed by dashboard health indicators.

## Tasks / Subtasks
- [ ] Extend scheduler (Story 3.1) to classify errors and apply retry policy (AC 1, AC 2).
- [ ] Instrument telemetry emitter with attempt metadata (AC 3).
- [ ] Publish SSE `ingestion.failed` with payload `{ clientId, sourceId, attempt, reason }` (AC 4).
- [ ] Add unit tests for retry/backoff calculations and permanent error detection (AC 1, AC 2).
- [ ] Update runbook with troubleshooting steps referencing telemetry dashboards (AC 3).

## Dev Notes
- For HTTP 429, respect `Retry-After` header when present.
- Coordinate with Source Health story for consistent status messaging.

### Testing
- Use mocked HTTP responses to simulate failure classes.
- Validate SSE payload via integration test harness.

## Change Log
| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-03-29 | 0.1 | Draft for Epic: Ingestion & Normalization. | PM |

## Dev Agent Record
_Not yet worked._
