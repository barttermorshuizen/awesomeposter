# Story 3.1: Scheduled Source Fetching

## Status
Draft

## Story
**As the** discovery ingestion service,
**I want** to fetch client sources on their configured cadence without overlapping runs,
**so that** normalized items stay fresh and reliable.

## Acceptance Criteria
1. Each source stores a fetch interval (default 60 minutes) and scheduler respects it with no overlapping jobs per source.
2. Scheduler selects the appropriate fetch adapter for HTTP pages, RSS feeds, and YouTube channels/playlists based on the source configuration.
3. Concurrent fetches for different sources are allowed but capped to configurable worker pool size.
4. Scheduler records job start/end timestamps and success/failure to telemetry.
5. Failures (network, HTTP status â‰¥400, YouTube API errors) are logged with reason codes and retried according to backoff policy defined in Story 3.3.

## Tasks / Subtasks
- [ ] Implement scheduler using existing job framework (`packages/agents-server` or `server/jobs`) with pluggable adapters per source type (AC 1, AC 2).
- [ ] Persist per-source next-run timestamp and update atomically after each job (AC 1).
- [ ] Add worker pool configuration (env) and guard to prevent overrun (AC 3).
- [ ] Emit telemetry events `ingestion.started` / `ingestion.completed` including source type metadata (AC 4).
- [ ] Document scheduling behavior in runbook, highlighting RSS and YouTube cadence considerations (AC 1-5).

## Dev Notes
- Consider using BullMQ or existing queue; coordinate with infra team.
- Ensure scheduler is resilient across restarts (persist state in DB, not memory).

### Testing
- Integration tests mocking HTTP responses to confirm scheduling/backoff.
- Use fake timers to simulate long-running schedules.

## Change Log
| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-03-29 | 0.1 | Draft for Epic: Ingestion & Normalization. | PM |

## Dev Agent Record
_Not yet worked._
